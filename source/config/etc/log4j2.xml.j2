{% set java_log_severity = 'INFO' if fds_log_severity is not defined
       			   	   else 'TRACE' if fds_log_severity == 'trace'
       			   	   else 'DEBUG' if fds_log_severity == 'debug'
       			   	   else 'DEBUG' if fds_log_severity == 'io'
       			   	   else 'INFO' if fds_log_severity == 'normal'
       			   	   else 'INFO' if fds_log_severity == 'notification'
       			   	   else 'WARN' if fds_log_severity == 'warning'
       			   	   else 'ERROR' if fds_log_severity == 'error'
       			   	   else 'FATAL' if fds_log_severity == 'critical'
				   else 'INFO'
%}
{% block content %}
<?xml version="1.0" encoding="UTF-8"?>
<Configuration monitorInterval="30">
    <Properties>
        <!-- {{ ansible_managed }} -->
        <!-- must match environment variable name -->
        <property name ="fds_root">/fds</property>
        <property name="fds.service.name">default</property>

        <!-- Current code uses 'yyyy-MM-dd'T'HH:mm:ss.SSSSSSZZZ' date format which
             is ISO8601 plus greater precision and including timezone offset.
             docs claim using a pattern instead of the predefined defaults (ISO8601)
             negatively impact performance.  Something to consider if logging is
             ever identified as a bottleneck.-->
        <Property name="fds.pattern">%d{yyyy-MM-dd'T'HH:mm:ss.SSSSSSZZZ} - %5p %c %t - %m%n</Property>

        <!-- intent here is to use the env definition of fds_root.  If not set, should
             default to /fds based on above definition -->
        <property name="fds.logs">${env:fds_root}/var/logs</property>

    </Properties>
    <Appenders>

        <!-- log4j2 docs show filePattern using variables like
            "filePattern="logs/$${date:yyyy-MM}/app-%d{yyyy-MM-dd}-%i.log.gz"
            to archive files.  The $${date:yyyy-MM} portion of that is supposed to create
            a directory based on the month, but is instead creating a directory named "${date:yyyy-MM}".
            Replacing with a fixed name for now -->
        <!-- Note also that we are only using an index (%i) in the file name pattern.  This was
            chosen in part because the Log4j2 max files rollover strategy is currently based only
            on the index, but when using a TimeBasedTriggeringPolicy (and a datetime pattern in the
            file pattern), that index resets when the file rolls based on time.  The result is that the
            max files is not respected.  There are alternatives, such as creating our own policies, or
            doing log file management outside of the library, but this seems like an ok default -->
        <RollingRandomAccessFile name="fds-${sys:fds.service.name}"
                                 fileName="${fds.logs}/${sys:fds.service.name}.log"
                                 filePattern="${fds.logs}/archive/${sys:fds.service.name}-%i.log.gz"
                                 immediateFlush="true">

            <Policies>
                <!-- start a new file at startup regardless of time or size -->
                <OnStartupTriggeringPolicy/>

                <!-- rollover when file size reaches 100 MB -->
                <SizeBasedTriggeringPolicy size="100 MB"/>
            </Policies>
            <DefaultRolloverStrategy max="100"/>
            <PatternLayout pattern="${fds.pattern}"/>
        </RollingRandomAccessFile>

        <Console name="console" target="SYSTEM_OUT">
            <PatternLayout pattern="%d %-5p [%t] %c{2} (%F:%L) - %m%n"/>
        </Console>
    </Appenders>

    <!-- Filters/Markers appear to be required at the configuration.  They can
         possibly applied at the logger level to override the config setting.
          https://issues.apache.org/jira/browse/LOG4J2-601
    -->
    <Filters>
        <!-- HttpRequest Log Filters used in the com.formationds.web.toolkitRequestLog.  
            Note that when enabled these produce a lot of output extra log output and will
            cause logs to rollover frequently.
        <MarkerFilter marker="REQUEST" onMatch="ACCEPT" onMismatch="NEUTRAL" />
        <MarkerFilter marker="REQUEST_QUERY" onMatch="ACCEPT" onMismatch="NEUTRAL" />
        <MarkerFilter marker="REQUEST_HEADERS" onMatch="DENY" onMismatch="NEUTRAL" />
        <MarkerFilter marker="REQUEST_PAYLOAD" onMatch="ACCEPT" onMismatch="NEUTRAL" />
        <MarkerFilter marker="REQUEST_PAYLOAD_INGEST_STATS" onMatch="DENY" onMismatch="NEUTRAL" />
    </Filters>

    <Loggers>
        <Root level="WARN">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Root>
        <Logger name="com.formationds" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>
        
        <Logger name="com.formationds.om.repository.influxdb.InfluxDBConnection$LoggingInfluxDBReader" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>        
        <Logger name="com.formationds.om.repository.influxdb.InfluxDBConnection$LoggingInfluxDBWriter" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>
        
        <Logger name="com.formationds.platform" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>
        
        <!-- The RequestLog logs detailed information about each request optionally including headers and
             payload.  Enable by setting the level to TRACE and setting the markers onMatch for the fields
             you want logged to ACCEPT.  Although every attempt is made to prevent logging sensitive information
             there is a possibility that some information logged may be considered sensitive.  Be sure to
             secure your logs.
         -->
        <Logger name="com.formationds.web.toolkit.RequestLog" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>

        <!-- StatisticPublisher TRACE level will dump every statistic value received by the AM (XDI) 
          to the log file. -->
        <Logger name="com.formationds.am.StatisticsPublisher" level="{{ java_log_severity }}" additivity="false">
            <AppenderRef ref="fds-${sys:fds.service.name}"/>
        </Logger>        
    </Loggers>
</Configuration>
{% endblock %}
