#!/usr/bin/python
import sys
import os
import time
sys.path.append('../../test')
sys.path.append('../fdslib/pyfdsp')

from svc_api import ttypes
from thrift import TSerialization
from thrift.protocol import TJSONProtocol

import json
import jsonpickle
import copy
import random
from tabulate import tabulate
from tornado.httpclient import *
import tornado.web
import tornado.ioloop

NUMBER_OF_OPS = 3
MAGIC_WORD = 'magic_word'
HEADER_SIZE = 4000
DEBUG_TIMEOUT = 5

operation_list=[]

class Processor(object):
    """ Converts the primitive operations generated by workload generator into sendable messages."""
    def __init__(self, list_):
        self.list_ = list_

    def readData(self, input_=sys.stdin):
        """ Reads a single object from standard input. """
        _dedup_ratio = 0
        _size = 0
        _obj_id = ''

        # Populate header data
        while True:
            line = input_.readline()
            if not line: break

            # strip newline char
            line = line.rstrip()

            # start parsing once magic word is detected
            if line == MAGIC_WORD:
                _dedup_ratio = int(input_.readline())
                _size = int(input_.readline())
                _obj_id = input_.readline().rstrip()
                break

        # Return the tuple of data id, dedup ratio, and actual data
        return (_obj_id, _dedup_ratio, input_.read(_size))

    def toJson(self):
        """ Returns a list of messages usable by JSon decoders."""
        ret_list = []
        for operation in self.list_:
            if operation == 'put':
                pass
            elif operation == 'get':
                pass
            elif operation == 'delete':
                pass

    def handle_request(self, response):
        print response.effective_url, response.code, response.body

    def toHTTP(self, fds_url='http://localhost:8000/bucket1/'):
        """ Handles sending async HTTP requests to AM. """
        data_list = []
        http_client = AsyncHTTPClient()

        _get_counter=0
        _del_counter=0
        _fake_del_obj='fake1'
        _fake_del_ctr=1
        _fake_get_obj='fake1'
        _fake_get_ctr=1

        # Send HTTP requests asynchronously
        for operation in self.list_:
            if operation == 'put':
                _data = self.readData()
                data_list.append((_data[0], _data[1]))  # (obj id, dedup ratio)
                http_client.fetch(
                        HTTPRequest(fds_url+_data[0],
                            method='PUT',
                            body=_data[2]),
                        callback=self.handle_request)
                #futures.append((
                #    session.put(fds_url+_data[0], data=_data[2], timeout=DEBUG_TIMEOUT),
                #    _data[0],
                #    'put'))
            elif operation == 'get':
                try:
                    http_client.fetch(
                            HTTPRequest(fds_url+data_list[_get_counter][0],
                                method='GET'),
                            callback=self.handle_request)
                    #futures.append((
                    #    session.get(fds_url+data_list[_get_counter][0], timeout=DEBUG_TIMEOUT),
                    #    data_list[_get_counter][0],
                    #    'get'))
                except IndexError as y:
                    http_client.fetch(
                            HTTPRequest(fds_url+_fake_get_obj,
                                method='GET'),
                            callback=self.handle_request)
                    #futures.append((
                    #    session.get(fds_url+_fake_get_obj, timeout=DEBUG_TIMEOUT),
                    #    _fake_get_obj,
                    #    'get'))
                    _fake_get_ctr += 1
                    _fake_get_obj = 'fake'+str(_fake_get_ctr)
                else:
                    _get_counter += 1
            elif operation == 'delete':
                try:
                    http_client.fetch(
                            HTTPRequest(fds_url+data_list[_del_counter][0],
                                method='DELETE'),
                            callback=self.handle_request)
                    #futures.append((
                    #    session.delete(fds_url+data_list[_del_counter][0], timeout=DEBUG_TIMEOUT),
                    #    data_list[_del_counter][0],
                    #    'del'))
                except IndexError as y:
                    http_client.fetch(
                            HTTPRequest(fds_url+_fake_del_obj,
                                method='DELETE'),
                            callback=self.handle_request)
                    #futures.append((
                    #    session.delete(fds_url+_fake_del_obj, timeout=DEBUG_TIMEOUT),
                    #    _fake_del_obj,
                    #    'del'))
                    _fake_del_ctr += 1
                    _fake_del_obj = 'fake'+str(_fake_del_ctr)
                else:
                    _del_counter += 1

        # Process the responses.  This is blocking
        _tab = []
        _header = ['Obj Name','Op','HTTP Error Code','Error Text']
        #for future in futures:
        #    try:
        #        _tmp = [future[1],future[2],str(future[0].result()),str(future[0].result().text)]
        #        _tab.append(_tmp)
        #    except requests.RequestException as e:
        #        _tmp = [future[1],future[2],str(e)]
        #        _tab.append(_tmp)
        print tabulate(_tab, _header)
        #tornado.ioloop.IOLoop.instance().start()

        return data_list

    def toAB(self):
        ret_list = []
        for operation in self.list_:
            if operation == 'put':
                pass
            elif operation == 'get':
                pass
            elif operation == 'delete':
                pass

class Spec(object):
    """ Encapsulates the order in which operations should occur."""
    put=0
    get=0
    delete=0
    io=0
    rand_seed=0
    order=''

class Workload(object):
    """ Handles loading and creation of test workloads."""

    def __init__(self, pathToConfig):
        """ Reads in config file and sets Spec variables."""
        try:
            f = open(pathToConfig,'r')
        except EnvironmentError as e:
            print e
        else:
            with f:
                self.spec = Spec()
                j = json.load(f)
                self.spec.put = j['put']
                self.spec.get = j['get']
                self.spec.delete = j['del']
                self.spec.rand_seed = j['rand_seed']
                self.spec.io = j['total_io']
                self.spec.order = j['order']

    def print_spec(self):
        """ Prints test workload spec."""
        print 'Spec for current workload:'
        print 'PUTS:',self.spec.put
        print 'GETS:',self.spec.get
        print 'DELS:',self.spec.delete
        print 'ORDER:',self.spec.order
        print 'TOTAL IO:',self.spec.io
        print 'RAND SEED:',self.spec.rand_seed

    def get_op_from_order(self, y):
        """ Maps order string to operation strings."""
        if y == 'p':
            return 'put'
        elif y == 'g':
            return 'get'
        elif y == 'd':
            return 'delete'

    def generate(self):
        """ Generates list of commands to be executed in order."""
        self.load=[]
        random.seed(self.spec.rand_seed)
        _order=0
        _spec=Spec()
        _spec.__dict__.update(self.spec.__dict__)
        _repeat=False
        _list=list(_spec.order)

        if self.spec.rand_seed != 0:
            random.shuffle(_list)
            _spec.order = ''.join(_list)
        for i in range(self.spec.io):
            # Add a command based on order.  order resets after three ops
            self.load.append(self.get_op_from_order(_spec.order[_order]))
            _spec.__dict__[self.get_op_from_order(_spec.order[_order])] -= 1

            # If there are still ops on current op type repeat this op type
            if _spec.__dict__[self.get_op_from_order(_spec.order[_order])] > 0:
                _repeat = True
            else:
                _repeat = False

            # If there are no ops left proceed to the next op and reset _spec
            if _repeat is False:
                _order = (_order + 1) % NUMBER_OF_OPS
                if _order is NUMBER_OF_OPS-1:
                    _spec.__dict__.update(self.spec.__dict__)
                    random.shuffle(_list)
                    _spec.order = ''.join(_list)


def main():
    """ Runs workload generator with JSon spec as first argument."""
    # Create a test volume
    try:
        print requests.put('http://localhost:8000/bucket1')
    except Exception as e:
        print 'Bucket create failed!'

    w = Workload(sys.argv[1])
    w.print_spec()
    w.generate()
    print w.load
    p = Processor(w.load)

    #try:
    #    print requests.delete('http://localhost:8000/bucket1')
    #except Exception as e:
    #    print 'Bucket delete failed!'

    #import timeit
    #print(timeit.timeit('p.toHTTP()', setup='gc.enable();from __main__ import Processor, Workload; w = Workload("spec.json"); w.generate(); p = Processor(w.load)', number=1))

if __name__ == '__main__':
    tornado.ioloop.IOLoop.instance().run_sync(main())
