#
# Copyright 2015 Formation Data Systems, Inc.
#
# Defines resource, configuration and steps to test
# Data persistence across restarts. First, we restart after an
# ungraceful "kill" of all domain services, and then we do
# it again after a graceful "shutdown" of services.
#
#
# Note: Do not embed white space in comma delimited lists - test framework bug.

# TEST RESOURCES and TOPOLOGY

[user]
user_name       = root
password        = passwd


# Use this section to support installation from a deployable package.
[install]
# Where's the Ansible deployment script? (Can be a path relative to where the test is started.)
deploy-script-dir = ../../../ansible/scripts
# Which script?
deploy-script   = deploy_fds.sh
# Where's the Ansible inventory template file?
inventory-template = ansible-inventory/generic-lxc-nodes
# Is the deployable package pulled from a dev environment(local) or the nightly build (nightly)?
deb-location    = nightly



# The 'node' section defines a nodes parameters. The section must be prefixed
# with 'node' but is also used as a unique ID for the node.
#
[node1]
om              = true
redis           = true
influxdb        = true
ip              = localhost
#ip              = lxc-node-01
fds_root        = /fds/node1
fds_port        = 7000
services        = sm,dm,am

[node2]
enable          = true
ip              = localhost
#ip              = lxc-node-02
fds_root        = /fds/node2
fds_port        = 7100
services        = sm,dm,am

[node3]
enable          = true
ip              = localhost
#ip              = lxc-node-03
fds_root        = /fds/node3
fds_port        = 7200
services        = sm,dm,am

[node4]
enable          = true
ip              = localhost
#ip              = lxc-node-04
fds_root        = /fds/node4
fds_port        = 7300
services        = sm,dm,am

# The 'volume' section defines a volume
[volume1]
# Name of the client AM to attach to
client = node1
# Apparently meant to be the Tenant ID.
id     = 1
# The size of the volume
size   = 10000
# The volume access type, currently either 'object' or 'block'
access = object

# The 'volume' section defines a volume
[volume2]
# Name of the client AM to attach to
client = node1
# Apparently meant to be the Tenant ID.
id     = 3
# The size of the volume
size   = 10000000
# The volume access type, currently either 'object' or 'block'
access = block

# TEST STEPS or CASES or SCENARIOS
# Names must be unique otherwise last stanza w/ the same name is used for all
# scenario steps with that name


#
# First, make sure we start cleanly by cleaning up any residual from
# a previous test.
#
[scenario_verify_domain_down]
log_marker      = Make sure no errant Services currently running and clean installation areas.
script          = [domain]
action          = kill_noverify-uninst

#
# Run the restart test "ungracefully".
#
[scenario_domain_install_boot_activate_ungraceful]
log_marker      = Install domain for 'kill' version.
script          = [domain]
action          = install-boot-activate

[scenario_wait_for_all_sm_ungraceful]
log_marker      = Wait for completion-DLT deployment
script          = [waitforlog]
fds_node        = node1
service         = om
logentry        = OM deployed DLT with 4 nodes
occurrences     = 1
maxwait         = 240

[scenario_create_volume1_ungraceful]
log_marker      = Create volume volume1
script          = [volume1]
action          = create
delay_wait      = 5

[scenario_create_volume2_ungraceful]
log_marker      = Create volume volume2
script          = [volume2]
action          = create
delay_wait      = 5

[scenario_getauthtoken_ungraceful]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_gets3conn_ungraceful]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_storeverifiableobject_ungraceful]
log_marker      = Store an object that we can later verify
script          = [testcases.TestS3IntFace.TestS3LoadVerifiableObject]
param_names     = bucket
params          = volume1

[scenario_addData_before_restart_ungraceful]
log_marker      = Write 4000 objects
script          = [testcases.TrafficGen.TestTrafficGen]
param_names     = hostname,n_reqs,test_type,username,volume_name
params          = localhost,4000,PUT,admin,volume1
delay_wait      = 60

[scenario_waitforobjectcreation_ungraceful]
log_marker      = Wait for object to propogate in system
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 5,to let created object become available in system

[scenario_checkverifiableobject_ungraceful]
log_marker      = Validate object before we restart the domain
script          = [testcases.TestS3IntFace.TestS3CheckVerifiableObject]
param_names     = bucket
params          = volume1

[scenario_closes3conn_ungraceful]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]

[scenario_domainshutdown_ungraceful]
log_marker      = Kill the domain ungracefully without cleaning
script          = [domain]
action          = kill_noverify

[scenario_verify_domain_after_kill_ungraceful]
log_marker      = Verify the domain is down after ungraceful shutdown.
script          = [verify]
state           = down
# Comma separated list of nodes.
#fds_nodes       = no fds-nodes option means check all nodes in the domain.

[scenario_add_sleep_for_sm_process_bootup]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = enable_sleep_before_migration.*, enable_sleep_before_migration = true

[scenario_boot_domain_after_stop_ungraceful]
log_marker      = Boot the domain without cleaning (no "install" option)
script          = [domain]
action          = boot-activate

[scenario_add_faultInjection_SM_ungraceful]
log_marker      = Set fault injection parameter on the source SM
script          = [testcases.TestFDSServiceMgt.TestServiceInjectFault]
# Command separated list of parameter names and values
param_names     = node,faultName
#params          = node2,sm.exit.before.client.erase
params          = node2,abort.sm.migration mark.object.store.unavailable resend.dlt.token.filter.set sm.exit.on.bringup sm.exit.before.client.erase sm.exit.sending.delta.set sm.objectstore.faults.init.firstphase sm.faults.senddeltaset abort.sm.migration.at.start abort.sm.migration.at.snap.cb fail.sm.migration.second.rebalance.req fail.sm.migration.sending.filter.set

# If we set SM state to unavailable, we need longer time to be able to do IO
# If the domain still resyncing on restart, we cannot change DLT at the same time,
# This means that if SM becomes unavailable right durign restart of the domain
# we will have to wait for few minutes before  we can do IO on the domain
# due to our consistency implementation
[scenario_waitfordomainsettling_ungraceful]
log_marker      = Allow some time for SMs to come up and domain to settle
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 300,to let domain settle and populate data

[scenario_gets3conn_after_restart_ungraceful]
log_marker      = Get an S3 connection after restart
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_checkverifiableobject_after_restart_ungraceful]
log_marker      = Validate object again after restart
script          = [testcases.TestS3IntFace.TestS3CheckVerifiableObject]
param_names     = bucket
params          = volume1

# Run the SM Checkers to see if all replicas match
[scenario_check_sm_objects_ungraceful]
log_marker      = Check all SMs.
script          = [testcases.SmChk.TestVerifyMigrations]

[scenario_addData_after_restart_ungraceful]
log_marker      = Write 4000 objects
script          = [testcases.TrafficGen.TestTrafficGen]
param_names     = hostname,n_reqs,test_type,username,volume_name
params          = localhost,4000,PUT,admin,volume1
delay_wait      = 60

[scenario_closes3conn_2_ungraceful]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]

[scenario_shutdown_and_clean_domain_ungraceful]
log_marker      = Shutdown and cleanup.
script          = [domain]
action          = kill-uninst

#
#
# Test restart after a "graceful" shutdown.
#
[scenario_reset_s3_obj]
log_marker      = Reset the S3 object for reuse.
script          = [testcases.TestS3IntFace.TestS3ObjReset]


[scenario_domain_install_boot_activategraceful]
log_marker      = Install domain for 'shutdown' version.
script          = [domain]
action          = install-boot-activate

[scenario_wait_for_all_sm_graceful]
log_marker      = Wait for completion-DLT deployment
script          = [waitforlog]
fds_node        = node1
service         = om
logentry        = OM deployed DLT with 4 nodes
occurrences     = 1
maxwait         = 240

[scenario_create_volume1_graceful]
log_marker      = Create volume volume1
script          = [volume1]
action          = create
delay_wait      = 5

[scenario_create_volume2_graceful]
log_marker      = Create volume volume2
script          = [volume2]
action          = create
delay_wait      = 5

[scenario_getauthtoken_graceful]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_gets3conn_graceful]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_storeverifiableobject_graceful]
log_marker      = Store an object that we can later verify
script          = [testcases.TestS3IntFace.TestS3LoadVerifiableObject]
param_names     = bucket
params          = volume1

[scenario_waitforobjectcreation_graceful]
log_marker      = Wait for object to propogate in system
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 5,to let created object become available in system

[scenario_checkverifiableobject_graceful]
log_marker      = Validate object before we restart the domain
script          = [testcases.TestS3IntFace.TestS3CheckVerifiableObject]
param_names     = bucket
params          = volume1

[scenario_closes3conn_graceful]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]

[scenario_domainshutdown_graceful]
log_marker      = Take domain down gracefully without cleaning
script          = [domain]
action          = shutdown

[scenario_waitfordomainshutdown_graceful]
log_marker      = Give some time for the domain to shutdown gracefully.
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 10,to allow the domain time to shutdown gracefully.

[scenario_verify_domain_after_shutdown_graceful]
log_marker      = Verify the domain is down after graceful shutdown.
script          = [verify]
state           = shutdown
# Comma separated list of nodes.
#fds_nodes       = no fds-nodes option means check all nodes in the domain.

[scenario_add_sleep_for_sm_process_bootup_graceful]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = enable_sleep_before_migration.*, enable_sleep_before_migration = true

[scenario_activate_domain_after_stop_graceful]
log_marker      = Activate the domain after shutdown
script          = [domain]
action          = graceful_restart

[scenario_add_faultInjection_SM_graceful]
log_marker      = From given fault injection points randomly set one on the source SM
script          = [testcases.TestFDSServiceMgt.TestServiceInjectFault]
# Command separated list of parameter names and values
param_names     = node,faultName
params          = node2,mark.object.store.unavailable resend.dlt.token.filter.set sm.exit.on.bringup sm.exit.before.client.erase sm.exit.sending.delta.set sm.objectstore.faults.init.firstphase sm.faults.senddeltaset abort.sm.migration.at.start abort.sm.migration.at.snap.cb fail.sm.migration.second.rebalance.req fail.sm.migration.sending.filter.set

# If we set SM state to unavailable, we need longer time to be able to do IO
# If the domain still resyncing on restart, we cannot change DLT at the same time,
# This means that if SM becomes unavailable right durign restart of the domain
# we will have to wait for few minutes before  we can do IO on the domain
# due to our consistency implementation
[scenario_waitfordomainsettling_graceful]
log_marker      = Allow some time for the domain to settle
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 300,to let domain settle and populate data

[scenario_gets3conn_after_restart_graceful]
log_marker      = Get an S3 connection after restart
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_checkverifiableobject_after_restart_graceful]
log_marker      = Validate object again after restart
script          = [testcases.TestS3IntFace.TestS3CheckVerifiableObject]
param_names     = bucket
params          = volume1

[scenario_addData_after_restart_graceful]
log_marker      = Load some data into volume1 "bucket" using the S3 interface
script          = [testcases.TestS3IntFace.TestS3LoadMBLOB]
# Command separated list of parameter names and values
param_names     = bucket
params          = volume1

[scenario_addMoreData_after_restart_graceful]
log_marker      = Load some data into volume2 "bucket" using the S3 interface
script          = [testcases.TestS3IntFace.TestS3LoadMBLOB]
# Command separated list of parameter names and values
param_names     = bucket
params          = volume2

[scenario_closes3conn_2_graceful]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]

[scenario_shutdown_and_clean_domain_graceful]
log_marker      = Shutdown and cleanup.
script          = [domain]
action          = kill-uninst

