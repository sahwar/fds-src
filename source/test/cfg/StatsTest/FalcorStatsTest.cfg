#
# Copyright 2016 Formation Data Systems, Inc.
#

# TEST DESCRIPTION
# This SysTest config expects a domain to be up and running.
#
# Given the domain, this SysTest will monitor volume stats for several volumes
# following some WRITEs to determine whether the numbers match expectations
# and match expectations over time. (Lately - 01/06/2016 - we've seen physical
# and/or logical byte counts for volumes go up and down over time despite
# there being no WRITE activity.)


[scenario_generate_large_file]
log_marker      = Generate a large file to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = falcor_large.generated
# 150M
arg.size        = 157286400

# 1.  Create 4 object volumes and 1 NFS volume
[scenario_create_objvol1]
log_marker      = Create volume volumeObj1
script          = [volumeObj1]
action          = create

[scenario_create_objvol2]
log_marker      = Create volume volumeObj2
script          = [volumeObj2]
action          = create

[scenario_create_objvol3]
log_marker      = Create volume volumeObj3
script          = [volumeObj3]
action          = create

[scenario_create_objvol4]
log_marker      = Create volume volumeObj4
script          = [volumeObj4]
action          = create

[scenario_create_nfsvol1]
log_marker      = Create volume volumeNfs1
script          = [volumeNfs1]
action          = create


# Set up our S3 authorization and connection
[scenario_get_auth_token]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_get_connection]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]


# Store the falcor file on "Volume 1" with the key:  falcor
[scenario_load_falcor_vol1_first_time]
log_marker      = Load file falcor on volume 1 for the first time
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj1
arg.verify      = true
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcor

# Wait for stat period to roll over.
[scenario_wait_1]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the same file again on "Volume 1" with the key: falcor2
[scenario_load_falcor_vol1_second_time]
log_marker      = Load file falcor on volume 1 for the second time with a different key
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj1
arg.verify      = true
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcor2

# Wait for stat period to roll over.
[scenario_wait_2]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the same file on "Volume 2" with multi-part upload using the key: falcor2
[scenario_load_falcor_vol2_only_time]
log_marker      = Load file falcor on volume 2 with S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj2
arg.verify      = true
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcor2

# Wait for stat period to roll over.
[scenario_wait_3]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the large generated file on "Volume 3" with the key: large
[scenario_load_large_vol3_only_time]
log_marker      = Load file falcor_large.generated on volume 3 for the one and only time
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj3
arg.verify      = true
arg.inputfile   = RESOURCES/falcor_large.generated
arg.key         = large

# Wait for stat period to roll over.
[scenario_wait_4]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Delete the falcor file on "Volume 1" with the key:  falcor
[scenario_delete_falcor_vol1]
log_marker      = Delete key falcor on volume 1
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj1
arg.verify      = true
arg.key         = falcor

# Wait for stat period to roll over.
[scenario_wait_5]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Repeat the above with volumes volumeObj3, volumeObj4, and volumeObj3
# in place of volumeObj1, volumeObj2, and volumeObj3 to get a good look
# at dedup stats.

# Store the falcor file on "Volume 2" with the key:  falcorx
[scenario_load_falcor_vol2_first_timex]
log_marker      = Load file falcor on volume 2 for the first time X
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj2
arg.verify      = false
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcorx

# Wait for stat period to roll over.
[scenario_wait_6]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the same file again on "Volume 2" with the key: falcor2x
[scenario_load_falcor_vol2_second_timex]
log_marker      = Load file falcor on volume 2 for the second time with a different key X
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj2
arg.verify      = false
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcor2x

# Wait for stat period to roll over.
[scenario_wait_7]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the same file on "Volume 3" with multi-part upload using the key: falcor2x
[scenario_load_falcor_vol3_only_timex]
log_marker      = Load file falcor on volume 3 with S3's multi-part upload X
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj3
arg.verify      = false
arg.inputfile   = RESOURCES/falcor.png
arg.key         = falcor2x

# Wait for stat period to roll over.
[scenario_wait_8]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Store the generated large file on "Volume 4" with the key: largex
[scenario_load_large_vol4_only_timex]
log_marker      = Load file falcor_large.generated on volume 4 for the one and only time X
script          = [testcases.TestS3IntFace.TestS3LoadFBLOB]
arg.bucket      = volumeObj4
arg.verify      = false
arg.inputfile   = RESOURCES/falcor_large.generated
arg.key         = largex

# Wait for stat period to roll over.
[scenario_wait_9]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Delete the falcor file on "Volume 2" with the key:  falcor
[scenario_delete_falcor_vol2x]
log_marker      = Delete key falcor on volume 2 X
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj2
arg.verify      = false
arg.key         = falcorx

# Wait for stat period to roll over.
[scenario_wait_10]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 60
arg.reason      = to let fine-grained stat period expire

# Finally, one multi-part upload of a file that will actually induce
# multiple parts.
[scenario_load_large_vol1_multi_part]
log_marker      = Load file falcor_large.generated on volume 1 with S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj1
arg.verify      = true
arg.inputfile   = RESOURCES/falcor_large.generated
arg.key         = large

# Wait at least 11 minutes for all stats output to appear.
[scenario_wait_for_stats]
script          = [testcases.TestMgt.TestWait]
arg.delay       = 660
arg.reason      = to let enough stats be collected for our canon check

[scenario_remove_large_file]
log_marker      = Remove the generated large file
script          = [testcases.TestMgt.TestRemoveFile]
arg.filename    = falcor_large.generated

# Kill nodes so that stats files don't change while we check them.
[scenario_kill_nodes]
log_marker      = Kill domain to check stats output.
script          = [domain]
action          = kill

# Check stats output against canons.
[scenario_check_volumeObj1_stats]
log_marker      = Check stats for volumeObj1.
script          = [canonmatch]
canon           = Stats/3.stat_min.log
filetocheck     = /fds/node1/sys-repo/vol-stats/3/stat_min.log
adjustLines     = True

[scenario_check_volumeObj2_stats]
log_marker      = Check stats for volumeObj2.
script          = [canonmatch]
canon           = Stats/4.stat_min.log
filetocheck     = /fds/node1/sys-repo/vol-stats/4/stat_min.log
adjustLines     = True

[scenario_check_volumeObj3_stats]
log_marker      = Check stats for volumeObj3.
script          = [canonmatch]
canon           = Stats/5.stat_min.log
filetocheck     = /fds/node1/sys-repo/vol-stats/5/stat_min.log
adjustLines     = True

[scenario_check_volumeObj4_stats]
log_marker      = Check stats for volumeObj4.
script          = [canonmatch]
canon           = Stats/6.stat_min.log
filetocheck     = /fds/node1/sys-repo/vol-stats/6/stat_min.log
adjustLines     = True


# Boot domain back up.
[scenario_boot_domain]
log_marker      = Boot domain to leave it in the state we found it
script          = [domain]
action          = boot
