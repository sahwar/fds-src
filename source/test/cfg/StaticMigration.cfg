#
# Copyright 2015 Formation Data Systems, Inc.
#
# Defines resource, configuration and steps to test
# Static Migration.
#
# Note: Do not embed white space is comma delimited lists - test framework bug.

# TEST RESOURCES and TOPOLOGY

[user]
user_name       = root
password        = passwd

# The 'node' section defines a nodes parameters. The section must be prefixed
# with 'node' but is also used as a unique ID for the node.
#
[node1]
# Denotes this node will run an OM. Therefore, it is enabled automatically.
om              = true
# We'll start Redis with this node. Since all the other nodes listed
# here are on the same machine, we don't need to specify Redis for
# boot up on them.
redis           = true
# start influxdb
influxdb        = true
# IP of the node
ip              = localhost
# Fds root directory to use
fds_root        = /fds/node1
# Base port for that node, not needed if we don't run all nodes one physical machine
fds_port        = 7000
# By default we get all services on a node. Otherwise we' specify a 'services' option.

[node2]
enable          = true
ip              = localhost
fds_root        = /fds/node2
fds_port        = 7100
services        = dm,sm

[node3]
enable          = true
ip              = localhost
fds_root        = /fds/node3
fds_port        = 7200
services        = dm,sm

[node4]
enable          = true
ip              = localhost
fds_root        = /fds/node4
fds_port        = 7300
services        = dm,sm

# The 'volume' section defines a volume
[volume1]
# Name of the server AM node to attach to
client = node1
# Apparently meant to be the Tenant ID.
id     = 1
# The size of the volume
size   = 10000
# The volume access type, currently either 'object' or 'block'
access = object

# The 'volume' section defines a volume
[volume2]
# Name of the server AM node to attach to
client = node1
# Apparently meant to be the Tenant ID.
id     = 2
# The size of the volume
size   = 10000
# The volume access type, currently either 'object' or 'block'
access = object

# The 'volume' section defines a volume
[volume3]
# Name of the server AM node to attach to
client = node1
# Apparently meant to be the Tenant ID.
id     = 3
# The size of the volume
size   = 10000000
# The volume access type, currently either 'object' or 'block'
access = block

# TEST STEPS or CASES or SCENARIOS
# Will be ordered according to scenario name.

[scenario_kill_uninst]
log_marker      = First clean up installation areas.
script          = [domain]
action          = kill-uninst

[scenario_install]
log_marker      = Install
script          = [node1]
action          = install

[scenario_disable_restart_failed_children_processes_node1]
log_marker      = Change platform.conf to not restart killed processes automatically
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = restart_failed_children_processes.*, restart_failed_children_processes = false,node1

[scenario_change_platform_1]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = prevent_adding_dm_after_startup.*,prevent_adding_dm_after_startup = false,node1

[scenario_change_platform_2]
log_marker      = Change global platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node,applyAll
params          = enable_feature.*,enable_feature = true,node1,1

[scenario_change_platform_3]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = enable_feature.*,enable_feature = true,node1

[scenario_change_platform_4]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node,applyAll
params          = replica_factor.*,replica_factor=4,node1,1

[scenario_change_platform_5]
log_marker      = Change platform.conf
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = replica_factor.*,replica_factor=4,node1

[scenario_kill_node1]
log_marker      = Install
script          = [node1]
action          = kill

[scenario_start_node1]
log_marker      = Start a single node domain by bringing up node node1
script          = [node1]
action          = boot-activate

[scenario_verify_node1_up]
log_marker      = Verify node node1 is up
script          = [verify]
state           = up
# Comma separated list of nodes.
fds_nodes       = node1
delay_wait      = 10

[scenario_create_vol_policy]
log_marker      = Create a volume policy.
script          = [policy1]
action          = create
delay_wait      = 10

[scenario_create_vol1]
log_marker      = Create volume volume1
script          = [volume1]
action          = create
delay_wait      = 10

[scenario_attach_vol1]
log_marker      = Attach volume volume1
script          = [volume1]
action          = attach

[scenario_create_vol2]
log_marker      = Create volume volume2
script          = [volume2]
action          = create
delay_wait      = 10

[scenario_attach_vol2]
log_marker      = Attach volume volume2
script          = [volume2]
action          = attach

[scenario_create_vol3]
log_marker      = Create volume volume3
script          = [volume3]
action          = create
delay_wait      = 10

[scenario_attach_vol3]
log_marker      = Attach volume volume3
script          = [volume3]
action          = attach

[scenario_get_s3_auth]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_get_s3_conn]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_load_data_vol1]
log_marker      = Load some data into volume1 "bucket" using the S3 interface
script          = [testcases.TestS3IntFace.TestS3LoadMBLOB]
# Command separated list of parameter names and values
param_names     = bucket
params          = volume1

[scenario_load_data_vol2]
log_marker      = Load some data into volume2 "bucket" using the S3 interface
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
# Command separated list of parameter names and values
param_names     = bucket
params          = volume2

[scenario_install_node2]
log_marker      = install on node2
script          = [node2]
action          = install

[scenario_disable_restart_failed_children_processes_node2]
log_marker      = Change platform.conf to not restart killed processes automatically
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = restart_failed_children_processes.*, restart_failed_children_processes = false,node2

[scenario_activate_node2]
log_marker      = Boot and activate node2
script          = [node2]
action          = boot-activate


[scenario_wait_for_node2_activation]
log_marker      = Wait for node 2 activation completion
script          = [waitforlog]
fds_node        = node2
service         = sm
logentry        = :NotifyDLTCloseCb
occurrences     = 1
maxwait         = 240

[scenario_wait_for_migration_msgs_node1]
log_marker      = Wait for migration client messages
script          = [waitforlog]
fds_node        = node1
service         = dm
logentry        = Creating migration client
occurrences     = 4
maxwait         = 120

[scenario_wait_for_migration_msgs_node2]
log_marker      = Wait for migration client messages
script          = [waitforlog]
fds_node        = node2
service         = dm
logentry        = Migration executor received
occurrences     = 4
maxwait         = 120

[scenario_wait_for_processdeltablobs_node2]
log_marker      = Wait for at least one processingdeltablobs msg
script          = [waitforlog]
fds_node        = node2
service         = dm
logentry        = Processing incoming CtrlNotifyDeltaBlobsMsg
occurrences     = 1
atleastone      = 1
maxwait         = 120

[scenario_verify_node1_node2_up]
log_marker      = Verify nodes node1 and 2 are up
script          = [verify]
state           = up
# Comma separated list of nodes.
fds_nodes       = node1,node2
delay_wait      = 10


[scenario_install_node3]
log_marker      = install on node3
script          = [node3]
action          = install

[scenario_disable_restart_failed_children_processes_node3]
log_marker      = Change platform.conf to not restart killed processes automatically
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = restart_failed_children_processes.*, restart_failed_children_processes = false,node3

[scenario_activate_node3]
log_marker      = Boot and activate node3
script          = [node3]
action          = boot-activate

[scenario_wait_for_node3_activation]
log_marker      = Wait for node 3 activation completion
script          = [waitforlog]
fds_node        = node3
service         = sm
logentry        = :NotifyDLTCloseCb
occurrences     = 1
maxwait         = 240

[scenario_wait_for_migration_msgs_node3]
log_marker      = Wait for migration client messages
script          = [waitforlog]
fds_node        = node3
service         = dm
logentry        = Migration executor received
occurrences     = 4
maxwait         = 120

[scenario_wait_for_processdeltablobs_node3]
log_marker      = Wait for at least one processingdeltablobs msg
script          = [waitforlog]
fds_node        = node3
service         = dm
logentry        = Processing incoming CtrlNotifyDeltaBlobsMsg
occurrences     = 1
atleastone      = 1
maxwait         = 120

[scenario_verify_node1_2_3_up]
log_marker      = Verify nodes node1, 2, and 3 are up
script          = [verify]
state           = up
# Comma separated list of nodes.
fds_nodes       = node1,node2,node3
delay_wait      = 10

[scenario_install_node4]
log_marker      = install on node4
script          = [node4]
action          = install

[scenario_disable_restart_failed_children_processes_node4]
log_marker      = Change platform.conf to not restart killed processes automatically
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string,node
params          = restart_failed_children_processes.*, restart_failed_children_processes = false,node4

[scenario_activate_node4]
log_marker      = Boot and activate node4
script          = [node4]
action          = boot-activate

[scenario_wait_for_node4_activation]
log_marker      = Wait for node 4 activation completion
script          = [waitforlog]
fds_node        = node4
service         = sm
logentry        = :NotifyDLTCloseCb
occurrences     = 1
maxwait         = 240

[scenario_wait_for_processdeltablobs_node4]
log_marker      = Wait for at least one processingdeltablobs msg
script          = [waitforlog]
fds_node        = node4
service         = dm
logentry        = Processing incoming CtrlNotifyDeltaBlobsMsg
occurrences     = 1
atleastone      = 1
maxwait         = 120

[scenario_verify_node1_2_3_4_up]
log_marker      = Verify nodes node1, 2, 3, and 4 are up
script          = [verify]
state           = up
# Comma separated list of nodes. No white space, please.
fds_nodes       = node1,node2,node3,node4
delay_wait      = 10

[scenario_wait_for_omdlt_deploy]
log_marker      = Wait for OM deploy DLT with 4 nodes
script          = [waitforlog]
fds_node        = node1
service         = om
logentry        = OM deployed DLT with 4 nodes
occurrences     = 1
maxwait         = 180

[scenario_wait_for_migration_msgs_node4]
log_marker      = Wait for migration client messages
script          = [waitforlog]
fds_node        = node4
service         = dm
logentry        = Migration executor received
occurrences     = 4
maxwait         = 120

[scenario_wait_for_processdeltablobs_node3_2ndtime]
log_marker      = Wait for at least one processingdeltablobs msg
script          = [waitforlog]
fds_node        = node4
service         = dm
logentry        = Processing incoming CtrlNotifyDeltaBlobsMsg
occurrences     = 1
atleastone      = 1
maxwait         = 120


# Not seeing this message. Is there a new one to look for?
#[scenario_7]
#log_marker      = Wait until node node2's log shows SM migration starting
#script          = [waitforlog]
## Node containing log to search.
#fds_node        = node2
## Service whose log is to be searched.
#service         = sm
## Log entry to search for.
#logentry        = Will migrate tokens from source SM
## Exactly the number of occurrences that must be found for success.
#occurrences     = 1
## Maximum time to wait for the search to be successful before giving up as failure.
#maxwait         = 60
[scenario_domainshutdown_graceful]
log_marker      = Take domain down gracefully without cleaning
script          = [domain]
action          = shutdown

[scenario_waitfordomainshutdown_graceful]
log_marker      = Give some time for the domain to shutdown gracefully.
script          = [testcases.TestMgt.TestWait]
param_names     = delay,reason
params          = 15,to allow the domain time to shutdown gracefully.

[scenario_dmchecker]
log_marker      = run dm checker
script          = [testcases.TestFDSSysVerify.TestDMChecker]

[scenario_9_1]
log_marker      = Check disk-map file for node 1.
script          = [canonmatch]
canon           = StaticMigration/node1.disk-map
filetocheck     = /fds/node1/dev/disk-map

[scenario_check_diskmap_node2]
log_marker      = Check disk-map file for node 2.
script          = [canonmatch]
canon           = StaticMigration/node2.disk-map
filetocheck     = /fds/node2/dev/disk-map

[scenario_check_diskmap_node3]
log_marker      = Check disk-map file for node 3.
script          = [canonmatch]
canon           = StaticMigration/node3.disk-map
filetocheck     = /fds/node3/dev/disk-map

[scenario_check_diskmap_node4]
log_marker      = Check disk-map file for node 4.
script          = [canonmatch]
canon           = StaticMigration/node4.disk-map
filetocheck     = /fds/node4/dev/disk-map

[scenario_check_sm_migration_node1_node2]
# Run SM checker and compare results.
log_marker      = Check SM Static Migration from node1 to node2.
# Try this one even if previous scenarios have failed just to see what happens.
script          = [testcases.TestFDSSysVerify.TestVerifySMStaticMigration]
# Comma separated list of parameter names and values. No white space, please.
# We'll go ahead with this one even if previous test cases have failed.
param_names     = node1,node2,skip
params          = node1,node2,False

[scenario_check_sm_migration_node1_node3]
log_marker      = Check SM Static Migration from node1 to node3.
script          = [testcases.TestFDSSysVerify.TestVerifySMStaticMigration]
# Comma separated list of parameter names and values. No white space, please.
param_names     = node1,node2
params          = node1,node3

[scenario_check_sm_migration_node1_node4]
log_marker      = Check SM Static Migration from node1 to node4.
script          = [testcases.TestFDSSysVerify.TestVerifySMStaticMigration]
# Comma separated list of parameter names and values. No white space, please.
param_names     = node1,node2
params          = node1,node4

[scenario_shutdown_domain_end]
log_marker      = Now clean up installation areas.
script          = [domain]
#action          = uninst
action          = shutdown
