#
# Copyright 2015 Formation Data Systems, Inc.
#
# TEST RESOURCES and TOPOLOGY

# This cfg files tests expunge feature by verifying number of sm objects got deleted after three gc runs

[user]
user_name = root
password = passwd

[node1]
om = true
redis = true
influxdb = true
ip = localhost
fds_root = /fds/node1
fds_port = 7000

[node2]
enable          = true
ip              = localhost
fds_root        = /fds/node2
fds_port        = 7100

[node3]
enable          = true
ip              = localhost
fds_root        = /fds/node3
fds_port        = 7200

[node4]
enable          = true
ip              = localhost
fds_root        = /fds/node4
fds_port        = 7300


[volumeObj]
client = node1
id     = 1
size   = 10000
access = object

# TEST STEPS or CASES or SCENARIOS
# Will be ordered according to scenario name.

[scenario_kill_and_clean_pre_install]
log_marker      = Kill and cleanup prior to installation
script          = [domain]
action          = kill-uninst

[scenario_install]
log_marker      = Install FDS
script          = [domain]
action          = install

[scenario_0_1_2_4]
log_marker      = Disable AM Caching with max_volume_data = 0
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = max_volume_data.*,max_volume_data = 0

[scenario_0_1_2_5]
log_marker      = Disable AM Caching with max_metadata_entries =0
script          = [testcases.TestFDSEnvMgt.TestModifyPlatformConf]
param_names     = current_string,replace_string
params          = max_metadata_entries.*,max_metadata_entries = 0

[scenario_boot_activate]
log_marker      = Bring up domain
script          = [domain]
action          = boot-activate

[scenario_create_volumeObj]
log_marker      = Create volume volumeObj
script          = [volumeObj]
action          = create
delay_wait      = 5

[scenario_generate_data_one]
log_marker      = Generate a large file "data_one" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_one.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_one

[scenario_generate_data_two]
log_marker      = Generate a large file "data_two" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_two.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_two

[scenario_generate_data_three]
log_marker      = Generate a large file "data_three" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_three.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_three

[scenario_generate_data_four]
log_marker      = Generate a large file "data_four" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_four.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_four

[scenario_generate_data_five]
log_marker      = Generate a large file "data_five" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_five.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_five

[scenario_generate_data_six]
log_marker      = Generate a large file "data_six" to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = data_six.generated
# size in bytes, so ~52MB
arg.size        = 52428800
arg.seed        = seed_six


################################# Put all generated random files in volume #############################################

[scenario_get_s3_auth_1]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario_get_s3_conn_1]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]

[scenario_load_one_volumeObj_multi_part]
log_marker      = Load file data_one.generated on volumeObj with key "one" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_one.generated
arg.key         = one

[scenario_load_two_volumeObj_multi_part]
log_marker      = Load file data_two.generated on volumeObj with key "two" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_two.generated
arg.key         = two

[scenario_load_three_volumeObj_multi_part]
log_marker      = Load file data_three.generated on volumeObj with key "three" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_three.generated
arg.key         = three

[scenario_load_four_volumeObj_multi_part]
log_marker      = Load file data_four.generated on volumeObj with key "four" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_four.generated
arg.key         = four

[scenario_load_five_volumeObj_multi_part]
log_marker      = Load file data_five.generated on volumeObj with key "five" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_five.generated
arg.key         = five

[scenario_load_six_volumeObj_multi_part]
log_marker      = Load file data_six.generated on volumeObj with key "six" using S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volumeObj
arg.verify      = true
arg.inputfile   = RESOURCES/data_six.generated
arg.key         = six

################## Delete more than 60% data from volume and verify remaining data is still available###################

[scenario_delete_data_one_from_volumeObj]
log_marker      = Delete > 60% data from from volumeObj, delete keys "one"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = one

[scenario_delete_data_two_from_volumeObj]
log_marker      = Delete >60% data from from volumeObj, delete key "two"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = two

[scenario_delete_data_three_from_volumeObj]
log_marker      = Delete >60% data from from volumeObj, delete key "three"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = three

[scenario_delete_data_four_from_volumeObj]
log_marker      = Delete >60% data from from volumeObj, delete key "four"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = four

[scenario_verifydata_on_volumeObj_five_1]
log_marker      = Compare file data_five.generated on volumeObj with available key five
script          = [testcases.TestS3IntFace.TestS3VerifyFBLOB]
arg.bucket      = volumeObj
arg.key         = five
arg.comparefile = RESOURCES/data_five.generated

[scenario_verifydata_on_volumeObj_six_1]
log_marker      = Compare file data_six.generated on volumeObj with available key six
script          = [testcases.TestS3IntFace.TestS3VerifyFBLOB]
arg.bucket      = volumeObj
arg.key         = six
arg.comparefile = RESOURCES/data_six.generated

############## Run GC three times and expect SM deleting objects after third run ############

[scenario_run_gc_1]
log_marker      = Run GC on domain first time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion_1]
log_marker      = Expect SM deletion test to fail, that is 0 objects deleted from sm
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
arg.expect_failure = true

[scenario_run_gc_2]
log_marker      = Run GC on domain second time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion_2]
log_marker      = Expect SM deletion test to fail, that is 0 objects deleted from sm
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
arg.expect_failure = true

[scenario_run_gc]
log_marker      = Run GC on domain third time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion]
log_marker      = Data should be is deleted from SM, so sm.objects.deleted > 0
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
# arg.expect_failure default value is false

[scenario_verifydata_on_volumeObj_five_2]
log_marker      = After token compaction, verify data_five.generated with key five
script          = [testcases.TestS3IntFace.TestS3VerifyFBLOB]
arg.bucket      = volumeObj
arg.key         = five
arg.comparefile = RESOURCES/data_five.generated

[scenario_verifydata_on_volumeObj_six_2]
log_marker      = After token compaction, verify data_six.generated with key six
script          = [testcases.TestS3IntFace.TestS3VerifyFBLOB]
arg.bucket      = volumeObj
arg.key         = six
arg.comparefile = RESOURCES/data_six.generated

# Run the SM Checkers to confirm migration.
[scenario_verify_sm_data]
log_marker      = Check SM Migration from all SMs.
script          = [testcases.SmChk.TestVerifyMigrations]

############## Delete ALl keys and expect SM deleting objects after third run ############

[scenario_delete_data_five_from_volumeObj]
log_marker      = Delete key "five"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = five

[scenario_delete_data_six_from_volumeObj]
log_marker      = Delete key "six"
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volumeObj
arg.verify      = true
arg.key         = six

[scenario_run_gc_4]
log_marker      = Run GC on domain fourth time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion_4]
log_marker      = Expect SM deletion test to fail, that is 0 objects deleted from sm
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
arg.expect_failure = true

[scenario_run_gc_5]
log_marker      = Run GC on domain fifth time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion_5]
log_marker      = Expect SM deletion test to fail, that is 0 objects deleted from sm
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
arg.expect_failure = true

[scenario_run_gc_6]
log_marker      = Run GC on domain sixth time
script          = [testcases.TestFDSExpungeMgt.TestRunGarbageCollector]

[scenario_sm_deletion_6]
log_marker      = Data should be is deleted from SM, so sm.objects.deleted > 0
script          = [testcases.TestFDSExpungeMgt.TestVerifySmDeletion]
# arg.expect_failure default value is false

#################### Close s3 connection, delete generated data and then domain kill, cleanup ##########################

[scenario_closes_s3_connection]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]

[scenario_remove_generated_data]
log_marker      = Remove randomly generated files
script          = [testcases.TestMgt.TestRemoveFile]
arg.filename    = data_one.generated,data_two.generated,data_three.generated,data_four.generated,data_five.generated,data_six.generated

[scenario_kill_and_clean]
log_marker      = Kill and clean the domain
script          = [domain]
action          = kill-uninst