#
# Copyright 2015 Formation Data Systems, Inc.
#
# Test volume functions with different media types as storage medium.
# Test garbage collection for different media types.

# Note: Maxwait parameter in reboot scenarios is in MINUTES.Depending on data available on luster `maxwait` might be greater than 20 min also
#1. Install-boot-activate domain, verify each service is running.
#2. Loading ~150MB data in volume1, let it run in background with fork
#3. Reboot node2, node3
#4. Do some IO for volume2
#5. Reboot node4 and node1(OM)
#6. Join back Forked Volume1 IO and verify content
#7. Delete key `large` from volume, close s3 connection, kill-uninstall
# TEST RESOURCES and TOPOLOGY

[user]
user_name       = root
password        = passwd

[node1]
om              = true
redis           = true
influxdb        = true
ip              = localhost
fds_root        = /fds
fds_port        = 7000

[node2]
enable          = true
ip              = localhost
fds_root        = /fds
fds_port        = 7000

[node3]
enable          = true
ip              = localhost
fds_root        = /fds
fds_port        = 7000

[node4]
enable          = true
ip              = localhost
fds_root        = /fds
fds_port        = 7000

[policy1]
id    = 1
iops_min = 100
iops_max = 500
priority = 1

[volume1]
client = node1
id     = 1
size   = 10000
policy = 1
access = object
media = ssd

[volume2]
client = node1
id     = 2
size   = 10000
policy = 1
access = object
media = hdd

# TEST STEPS or CASES or SCENARIOS
# Will be ordered according to scenario name.

[scenario_install_boot_activate]
log_marker      = Install the domain
script          = [domain]
action          = install-boot-activate

[scenario_domain_verifyUp]
log_marker      = Verify domain is up
script          = [verify]
state           = up

[scenario_createVol1]
log_marker      = Create volume volume1
script          = [volume1]
action          = create
delay_wait      = 3

[scenario_createVol2]
log_marker      = Create volume volume2
script          = [volume2]
action          = create
delay_wait      = 3

[scenario_generate_large_file]
log_marker      = Generate a large file to play with
script          = [testcases.TestMgt.TestGenerateFile]
arg.filename    = falcor_large.generated
# 157.28 MB
arg.size        = 157286400

[scenario_getAuthToken]
log_marker      = Get an S3 authorization token
script          = [testcases.TestOMIntFace.TestGetAuthToken]

[scenario2_gets3conn]
log_marker      = Get an S3 connection
script          = [testcases.TestS3IntFace.TestS3GetConn]


# Store the falcor file on "Volume 1" with the key:  large
[scenario_load_large_vol1_multi_part]
log_marker      = Load file falcor_large.generated on volume 1 with S3's multi-part upload
script          = [fork]
real-script     = [testcases.TestS3IntFace.TestS3LoadLBLOB]
arg.bucket      = volume1
arg.verify      = true
arg.inputfile   = RESOURCES/falcor_large.generated
arg.key         = large

[scenario_reboot_node2]
log_marker      = Reboot node2
script          = [node2]
action          = reboot
service         = sm,om
logentry        = Resync on restart completed,DmtCloseOkEvt Ready for DM Migration
maxwait         = 30

[scenario_reboot_node3]
log_marker      = Reboot node3
script          = [node3]
action          = reboot
service         = sm,om
logentry        = Resync on restart completed,DmtCloseOkEvt Ready for DM Migration
maxwait         = 30

[scenario_run_io]
log_marker      = Verify CRD I/O for volume volume2 and don't verify DELETEs
script          = [testcases.TestS3IntFace.TestS3VerifiableObjectLoop]
param_names     = bucket,runTime,retry,verifyDelete
params          = volume2,120.0,false,false

[scenario_reboot_node4]
log_marker      = Reboot node4
script          = [node4]
action          = reboot
service         = sm,om
logentry        = Resync on restart completed,DmtCloseOkEvt Ready for DM Migration
maxwait         = 30

[scenario_reboot_node1]
log_marker      = Reboot OM node node1
script          = [node1]
action          = reboot
service         = sm
logentry        = Resync on restart completed
maxwait         = 30

[scenario_join_scenario_load_large_vol1_multi_part]
log_marker      = Join "scenario_load_large_vol1_multi_part" forked test
script          = [join]
join_scenario   = scenario_load_large_vol1_multi_part

[scenario_compare_falcor_vol1]
log_marker      = Compare file falcor_large.generated on volume1 with S3's multi-part upload
script          = [testcases.TestS3IntFace.TestS3VerifyFBLOB]
arg.bucket      = volume1
arg.key         = large
arg.comparefile = RESOURCES/falcor_large.generated

# Delete the falcor file on "Volume 1" with the key:  large
[scenario_delete_falcor_key_vol1]
log_marker      = Delete key falcor on volume 1
script          = [testcases.TestS3IntFace.TestS3DelKey]
arg.bucket      = volume1
arg.verify      = true
arg.key         = large

[scenario_closes_s3_connection]
log_marker      = Close the S3 connection
script          = [testcases.TestS3IntFace.TestS3CloseConn]
