{% block content %}
################################################################################
### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ###
### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ###
###         WARNING WARNING WARNING WARNING WARNING WARNING WARNING          ###
###   This is automatically generated by Ansible - DO NOT make manual edits  ###
###              to this file, as they will be overwritten!                  ###
### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ###
### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! ###
################################################################################
# Ansible managed: /root/fds-src/source/config/etc/platform.conf.j2 modified on 2016-02-08 08:51:46 by root on nate-dev
fds: {
    /* Network interface that all fds nodes should have */
    nic_if="{{nic}}"

    /* Use genkey to generate a new one */
    aes_key="005ecbcf2a3ddf8fc634a43b8adb44cc"

    authentication=true

    ssl: {
        /* path relative to fds_root */
        keystore_path="etc/ssl/dev/keystore"
        keystore_password="exotic sparrow"
        keymanager_password="exotic sparrow"
    }

    disable_qos = false

    /* Feature toggles, use "common:" for features that propogate across components */
    feature_toggle: {
        common: {
            enable_timeline = true
            periodic_expunge = true
            enable_multi_om_support = true
            enable_multiplexed_services = false
            enable_subscriptions = false
            all_ssd = false
            volume_open_support = false

    	    /* Volume grouping allows IO to volumes to driven by a coordinator at AM */
    	    enable_volumegrouping = true

            /* Whether to serialize reads when volume grouping is on */
            volumegrouping_serializedreads = false

            /* If volume grouping mode is on, calculate 1 DMT version once # of DMs have matched */
            volumegrouping_dm_cluster_size = 4

	    /* Replication factor for volume metadata */
            volumegrouping_replica_factor = 3

    	    /* applies to OM and XDI web toolkit */
            enable_web_logging_request_wrapper = false

            send_to_new_stats_service = true
        }
        pm: {

            use_disk_hints = false
            control_disk_simulation_mode = false
            use_new_superblock = true
            restart_failed_children_processes = true
            enable_disk_activation = false
        }
        dm: {

        }
        sm: {

        }
        am: {
            scst_connector = true
            nbd_connector = true
            serialization = "volume"
            all_atomic_ops = false
            cache_missing_cat_entries = false
        }
        om: {
           allow_service_reregistration = true
           enable_java_om_svc_proxy = false
           rest_07_feature = true
           fs_2660_metric_firebreak_event_query = false
           enable_influxdb_write_batch = false
           enable_influxdb_chunked_query_response = false

           /* If both are enabled, then metrics are written to both and queries depend on
              the enable_influxdb_query_series_per_volume flag */

           /* default original implementation using a single series containing all volume metrics */
           enable_influxdb_one_series = true

           /* new implementation that uses a series per volume */
           enable_influxdb_series_per_volume = false

           /** if enabled, query from new series per volume implementation */
           enable_influxdb_query_series_per_volume = false

           /** if enabled, stats queries will now go to the stats service instead of influx **/
           enable_stats_service_query = false

           /** if enabled, om will write metrics into influx db **/
           enable_influx_persistence = true

           ignore_failed_svcs = true

           configsvc_rest_client_proxy_v08 = true
           use_shared_queryhelper = true

           /* if enabled, adds a web filter that checks if the domain is up before
             attempting to contact the configuration service for operations that require
             the domain is up */
           enable_domain_web_filter = false

           /* if enabled, will update DLT only when minimum number of SMs have come up */
           enforce_minimum_replicas = true
        }
    }

    /* Use this section for settings that are shared (or needed) by most or all processes */
    common: {

        om_ip_list = "{{ om_ip }}"
        om_port = 7004
        om_uuid = 1028

        stats_port = 11011

       
       
        /* Options when running under valgrind */
        valgrind: {
           enabled = false
           app_name = "valgrind"
           /* All paths relative to fds_root */
           base_dir = "memcheck/"
           common_options = "--show-reachable=no,--show-possibly-lost=no,--gen-suppressions=all,--tool=memcheck,--leak-check=yes,--num-callers=30,--xml=yes,-v"
           process_specific: {
                bare_am =    "--soname-synonyms=somalloc=*tcmalloc*"
                StorMgr =    "--soname-synonyms=somalloc=*tcmalloc*"
	   }
	   suppressions: {
                suppressions_option = "--suppressions="
                suppressions_suffix  = ".supp"
	   }
	   output: {
                results_option = "--xml-file="
                results_suffix = ".%p.memcheck"
	   }
        }
    }

    pm: {
        /* process id */
        id = "pm"

        /* Log file */
        logfile = "pm"

        /* Log severity */
        log_severity = "normal"

        /* Platform uuid.  From this base uuid other service runnig on this node detrive their uuids */
        platform_uuid = 1024

        /* Platform port.  This is the node base port.  All services running on this node derive their port based on this port */
        platform_port = 7000

        redis_host = "{{ om_ip }}"
        redis_port = 6379

        service_management: {
            /* If a service restarts flap_count times in flap_timeout seconds, PM will stop restarting the service and notify the OM */
            flap_count   = 5
            flap_timeout = 300  /* in seconds */
        }

        /* Force disk simulation_mode (enable Feature Toggle first) */
        /* true=simuation mode, false=auto detection */
        force_disk_simulation = false

        disk_sim: {
            ssd_count = 2
            hdd_count = 10
        }

        capabilities: {
            disk: {
                ssd: {
                    iops_min = 5000
                    iops_max = 10000
                }
                hdd: {
                    iops_min = 500
                    iops_max = 1000
                }
                /* GC..etc disk reservation */
                # reserved_space = 0.20
                reserved_space = 0.00
            }
        }

        threadpool: {
            num_threads = 10

            /* Use lock free threadpool  */
            use_lftp = true
        }

        /* Internal testing related info */
        testing: {
            standalone = false
            /* overwrite node capabilities from this config */
            manual_nodecap = true
            node_iops_max  = 100000
            node_iops_min  = 60000
        }

        /* Service layer stanza */
        svc: {
            lftp: {
                /* Enable lockfree threadpool optimizations or not */
                enable = false
                io_thread_cnt = 2
                worker_thread_cnt = 2
            }

            timeout: {
                thrift_message = 5000
            }
        }

        /* Graphite is enabled or not */
        enable_graphite = false

        graphite: {
            /* Graphite server ip */
            ip = "127.0.0.1"
            /* Graphite server port */
            port = 2003
            period = 5
        }

        /* used to launch services with environment variables set */
        environment: {
                /* expected format is "key1=val1;key2=val2;..." */
                am = ""
                dm = ""
                sm = ""
                xdi = ""
        }
    }

    dm: {
        svc: {
            lftp: {
                /* Enable lockfree threadpool optimizations or not */
                enable = false
                io_thread_cnt = 2
                worker_thread_cnt = 2
            }
            timeout: {
                thrift_message = 5000
            }
        }
        perf: { enable = true }

        qos: {
            /* Default qos threads */
            default_qos_threads = 10
            /* default max number of outstanding IO below qos control */
            default_outstanding_io = 20
        }

        catalog_write_buffer_size = 52428800
        catalog_cache_size =  16777216
        catalog_log_max_files = 5
        number_of_primary = 2
        req_serialization = true
        realtime_stats_sampling = false
        disk_fullness_threshold = 75

        /* process id */
        id      = "dm"
        no_om   = false;

        /* Log file */
        logfile = "dm"

        /* Log severity */
        log_severity = "normal"

            /* Lease time (seconds) for volume access tokens */
            token_lease_time=60

        cache: {
           /* Default max entries in a volume's DM catalog cache */
           default_max_entries = 200
        }

        migration: {
            /* Rsync username to use during migration */
            rsync_username = "root"
            /* Rsync password to use during migration */
            rsync_password = "passwd"

            /* boolean to enable/disable DM migration feature */
            enable_feature = true

            /* boolean to enable/disable DM resync feature */
            enable_resync = false

            /* timeout duration in sec */
            migration_timeout= 300

            /* Maximum concurrent migrations */
            migration_max_concurrency = 1

            /* Maximum number of blobs in delta set */
            migration_max_delta_blobs = 4096

            /* Timeout value (millisecs) for interval between receiving delta blob/blobsdesc msgs (should be less than migration_timeout) */
            migration_max_delta_blobs_to = 3600000

            /* Maximum number of blob desc in delta set */
            migration_max_delta_blob_desc = 4096
        }

        /* Graphite is enabled or not */
        enable_graphite = false

        graphite: {
            /* Graphite server ip */
            ip = "127.0.0.1"
            /* Graphite server port */
            port = 2003
            period = 5
        }

        threadpool: {
            num_threads = 10

            /* Use lock free threadpool  */
            use_lftp = true
        }

        upload_to_cloud = false

        /* Internal testing related info */
        testing: {
            standalone = false

            /* Forces all DM APIs to immediately return success */
            uturn_all = false

            /* Forces catalog update calls to immediately return success */
            uturn_updatecat = false

            /* Forces start tx calls to immediately return success */
            uturn_starttx = false

            /* Forces set metadata calls to immediately return success */
            uturn_setmeta = false

            /* For testing firebreak on shorter timescale */
            test_firebreak = false
            coarseslot_sec = 300
            coarse_slots = 6
            longslot_sec = 900
            long_slots = 6

            /* Delay the start the of the DM x seconds for testing migration injections */
            test_delay_start = 0
        }
    }

    sm: {
        svc: {
            lftp: {
                /* Enable lockfree threadpool optimizations or not */
                enable = false
                io_thread_cnt = 2
                worker_thread_cnt = 2
            }
            timeout: {
                thrift_message = 5000
            }
        }
        perf: { enable = true }

        /* process id */
        id      = "sm"
        prefix  = ""

        /* Log file */
        logfile="sm"

        /* Log severity */
        log_severity = "normal"

        /* verify data on datapath */
        data_verify = true
        /* verify data in background */
        data_verify_background = true

	/* Toggle for serializing requests for consistency */
        req_serialization = false
        /* Number of primary SMs; 0 means pre-consistency implementation */
        number_of_primary = 2

        /* daemonize or not */
        daemonize=true

        objectstore: {
            /* Size of the hashed task synchronizer */
            synchronizer_size = 100
            faults: {
                fail_writes = 0.0
            }
        }
        cache: {
            /* Default max number of data cache entries */
            default_data_entries = 0
            /* Default max number of metadata entries */
            default_meta_entries = 0;
        }

        qos: {
            /* Default qos threads */
            default_qos_threads = 10
            /* default max number of outstanding IO below qos control */
            default_outstanding_io = 20
        }

        /* Running in test mode */
        test_mode=false
        /* Internal testing related info */
        testing: {

            /* enable simulated latency with its timueout value */
            enable_mocking = false
            mocktimeout = 500
            /* enable if testing SM standalone, no dependency on platform and OM */
            standalone = false

            /* this is temporary until we fix platform, we don't want simulated SSDs */
            useSsdForMeta = false

           /* Use sync metadata write if true */
            syncMetaWrite = false

            /* General testing mode...should depricate */
            test_mode = false

            /* Number of volumes to create in test mode.  Valid when test_mode is true */
            test_volume_cnt=10

            /* Forces all SM APIs to immediately return success */
            uturn_all = false

            /* Forces put object calls to immediately return success */
            uturn_putobj = false

            /* if test_tier is enable, rank engine will be configured from the config below */
            test_tier = false
            /* number of objects in rank table (~ssd size) */
            rank_tbl_size = 1000
            /* how often re-ranking is done */
            rank_freq_sec = 300
            /* approx number of times an obj has to be accessed to become hot */
            hot_threshold = 3
            /* approx number of times an obj has to be accessed to become cold */
            cold_threshold = 0
            /* enable sleep from SM service registers with OM */
            enable_sleep_before_migration = false
            /* the duration of sleep(secs) before SM registers itself with OM */
            sleep_duration_before_migration = 150
        }
        threadpool: {
            num_threads = 10

            /* Use lock free threadpool  */
            use_lftp = true
        }
        /* Migration related info */
        migration: {
            /* size of the delta set from source SM to destination SM */
            max_delta_set_size = 16

            /* verify the integrity of the metadata and data  on destination SM */
            verify_migration_data = false

            /* boolean to enable/disable SM token migration feature */
            enable_feature = true

            /* boolean to enable/disable SM resync feature */
            enable_resync = true

            /* number of parallel sm migrations at a time */
            parallel_migration = 2
        }
        tiering: {
            hybrid: {
                enable                 = true
                /* Number of objects to move at a time */
                batchSz         = 1024
                /* In seconds to make testing easier (default 172800s = 2days) */
                frequency         = 604800
            }
        }
        /* Garbage Collection in SM */
        scavenger: {
             /* Maximum number of disks to compact at the same time */
             max_disks_compact = 2
             /* Time interval where GC periodically checks whether to GC or not */
             interval_seconds = 86400
             expunge_threshold = 3
             verify_data = true
        }

        /* Graphite is enabled or not */
        enable_graphite = false

        graphite: {
            /* Graphite server ip */
            ip = "127.0.0.1"
            /* Graphite server port */
            port = 2003
            period = 5
        }

    }

    am: {
        svc: {
            lftp: {
                /* Enable lockfree threadpool optimizations or not */
                enable = false
                io_thread_cnt = 2
                worker_thread_cnt = 2
            }
            timeout: {
                io_message = 25000
                open_message = 2500
                thrift_message = 5000
                coordinator_switch = 30000
            }
        }
        perf: { enable = true }

        /* process id */
            id = "am"

        log_severity = "normal"
        logfile      = "am"

        /* TODO(Rao): Get this from platform */
        om_config_port = 9090

        /* Graphite is enabled or not */
        enable_graphite = false

        graphite: {
            /* Graphite server ip */
            ip = "127.0.0.1"
            /* Graphite server port */
            port = 2003
            period = 5
        }

        s3_http_port_offset=1000
        s3_https_port_offset=1443
        swift_port_offset=2999
        am_base_response_port_offset=2876
        xdi_service_port_offset=1899
        streaming_port_offset=1911
        memory_backend=false
        qos_threads=4

        /* Frequency (seconds) to notify DM we are using a volume */
        token_renewal_freq=30

        connector: {
            nbd: {
                server_port_offset=3809
		threads=1
                options: {
                    /* Time (seconds) to retry connection to client before disconnect */
                    keep_alive=30
                    no_delay=true
                }
            }
            scst: {
		/* Smallest IO transfer size allowed */
                default_block_size=512

                /* Targets will appear with this prefix on iscsi portals */
                target_prefix="iqn.2012-05.com.formationds:"
            }
        }

        threadpool: {
            num_threads = 10

            /* Use lock free threadpool  */
            use_lftp = true
        }
        cache: {
            /* Default max data size in MiB per volume */
            max_volume_data =  400
            /* Default max entries in a volume's AM cache */
            max_metadata_entries =  200
            /* Default max staged entries in a volume's tx descriptor */
            tx_max_staged_entries = 10
        }

        /* Internal testing related info */
        testing: {
            /* Toggle stand alone mode */
            standalone = false

            /* Toggle to disable stats collection for metadata streaming */
            toggleDisableStreamingStats = false

            /* Forces all AM processor APIs to immediately return success */
            uturn_processor_all = false
            /* Forces all AM dispatcher APIs to immediately return success */
            uturn_dispatcher_all = false
            /* dipatchers timeout in us */
            uturn_dispatcher_timeout = 200
            /* Test mode to bypass local catalog cache */
            disable_vcc = true
            /* Forces all AM service APIs to immediately return success */
            uturn_amserv_all = false
            /* Forces AM service start transaction to immediately return success */
            uturn_amserv_starttx = false
            /* Forces AM service update blob to immediately return success */
            uturn_amserv_updateblob = false
            /* Forces AM service update metadata to immediately return success */
            uturn_amserv_updatemeta = false
            /* Forces AM service commit transaction to immediately return success */
            uturn_amserv_committx = false
            /* Forces AM service abort transaction to immediately return success */
            uturn_amserv_aborttx = false
            /* Forces AM service stat blob to immediately return success */
            uturn_amserv_statblob = false
            /* Forces AM service get blob to immediately return success */
            uturn_amserv_getblob = false
            /* Enables probe testing server */
            enable_probe = false
            /* Enable qos testing with probe, will use probe_outstanding_reqs per volume */
            probe_test_qos = false
            /* Number of threads for probe test */
            probe_num_threads = 10
            /* Number of max outanding requests */
            probe_outstanding_reqs = 500
            /* How long to sleep before checking the outstanding requests (periodically)*/
            probe_sleep_period = 500
            /* Enable printing of fine-grained QoS stats to var/stats/stats-data dir */
            print_qos_stats = false

            /* Fault injection toggles */
            fault: {
                /* Injects unreachable faults into service communication */
                unreachable = false
            }
        }
    }

    om:
    {
        /* Service layer stanza */
        svc: {
            lftp: {
                /* Enable lockfree threadpool optimizations or not */
                enable = false
                io_thread_cnt = 2
                worker_thread_cnt = 2
            }
            timeout: {
                thrift_message = 5000
            }
        }
        svc_event_threshold: {
            timeout: {
                threshold = 10
            }
        }

        /* Testing stanza */
        testing: {
                /* Toggle stand alone mode */
                standalone = false
        }
        id="om"
        prefix=""
        log_severity = "normal"
        logfile="om"
        config_port=9090
        config_cache_update_interval_ms=10000

        /* if om_enabled_java_om_svc_proxy feature toggle is enabled, then
           this property is used to determine the OM C++ Service port that is
           proxied from the primary OM service port.  This is considered an
           internal port to the OM and should not be accessed by any other
           service */
        java_svc_proxy_port_offset=1900

        xdi_response_port_offset=2988

        token_factor=8
        replica_factor=3
        placement_algo="ConsistHash"
        default_iops_min=0
        default_iops_max=0

        web_dir="../lib/admin-webapp/"
        http_port=7777
        https_port=7443
        configdb: {
            port=6379
        }

        influxdb: {
            url="http://127.0.0.1:8086"
            enable_query_backtrace = false
            serialize_writes=false
            write_batch_size = 1024
        }

        task_scheduler_pool: {
            min = 10
        }

        stats: {
            frequency=120
            duration=60
            method="POST"
        }

        test_mode=false
        threadpool: {
            num_threads = 10

            /* Use lock free threadpool  */
            use_lftp = true
        }

        snmp: {
            targetip = "localhost"
            community = "public"
        }
    }

    checker: {
        id = "checker"
        logfile = "checker"
        log_severity = "normal"

        /* Control path port */
        control_port = 6991

        enable_graphite = false

        threadpool: {
            num_threads = 10

            /* Use lock free threadpool */
            use_lftp = true
        }
    }

    xdi: {
        am_host = "localhost"
    	nfs_thread_pool_size = 64
	nfs_stats = true
	nfs_defer_metatada_updates = true
	nfs_max_live_nfs_cookies = 1000000
	am_timeout_seconds = 30
	am_retry_attempts = 100
	am_retry_interval_seconds = 5
	control_port_offset = 3200
    }

    test: {
        testing: {
            /* Toggle stand alone mode */
            standalone = true
        }
    }
}
{% endblock %}
